# -*- coding: utf-8 -*-
"""U-TILISE预训练模型.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XKG4IM8JtTOypxMgQwrFfGuE1035aYdk
"""

# !git clone https://github.com/prs-eth/U-TILISE.git
#
# !nvcc --version
#
# # !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
# !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
#
# !pip install torchdata
# !pip install torchtext
#
# !pip install -r requ.txt
# !pip install h5py==3.7
# !pip install ipywidgets==7.6
# !pip install ipykernel==6.15
# !pip install kornia==0.6.8
# !pip install matplotlib==3.6
# !pip install numba==0.55
# !pip install omegaconf==2.3
# !pip install tqdm==4.64
# !pip install wandb==0.13.9
# !pip install setuptools==61.2
# !pip install prodict==0.8.18
# !pip install torchgeometry==0.1.2
# !pip install tensorboard
# !pip install nestargs

# !pip install h5py
# !pip install ipywidgets
# !pip install ipykernel
# !pip install kornia
# !pip install matplotlib
# !pip install numba
# !pip install omegaconf
# !pip install tqdm
# !pip install wandb
# !pip install setuptools
# !pip install prodict
# !pip install torchgeometry
# !pip install tensorboard
# !pip install nestargs

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/U-TILISE

# !pip install torchinfo

# !pip install -U numba

import os
import sys
import torch
from matplotlib import pyplot as plt
from typing import Any, Dict

# /content/U-TILISE
from lib import config_utils
from lib import data_utils
from lib import visutils
from lib.eval_tools import (
    Imputation,
    visualize_att_for_one_head_across_time,
    visualize_att_for_target_t_across_heads
)
#
# !bash ./scripts/download_checkpoints.sh
#
# !bash ./scripts/download_data_earthnet2021.sh

def get_dataloader_testdata(
    config_file_train: str,
    config_file_test: str,
    run_mode: str = 'test'
) -> torch.utils.data.dataloader.DataLoader:
    if not os.path.isfile(config_file_train):
        raise FileNotFoundError(f'Cannot find the configuration file used during training: {config_file_train}\n')

    if not os.path.isfile(config_file_test):
        raise FileNotFoundError(f'Cannot find the test configuration file: {config_file_test}\n')

    # Read the configuration file used during training
    config = config_utils.read_config(config_file_train)

    # Merge generic data settings (used during training) with test-specific data settings
    config_testdata = config_utils.read_config(config_file_test)
    config.data.update(config_testdata.data)
    if 'mask' in config_testdata:
        config.mask.update(config_testdata.mask)
    config.misc.run_mode = run_mode

    # Get the data loader
    dset = data_utils.get_dataset(config, phase=run_mode)
    dataloader = torch.utils.data.DataLoader(
        dataset=dset, batch_size=1, shuffle=False, num_workers=8, drop_last=False
    )

    return dataloader


def get_sample(
    dataloader: torch.utils.data.dataloader.DataLoader,
    sample_index: int
) -> Dict[str, Any]:

    batch = dataloader.dataset.__getitem__(sample_index)

    # Introduce the batch dimension (required for the forward pass)
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            batch[k] = v.unsqueeze(0) # .unsqueeze(0) 会在维度 0（通常是批处理维度）上添加一个新的维度。
        elif isinstance(v, int):
            batch[k] = [v]

    return batch

"""## Imputation of satellite image time series with synthetic data gaps

<hr style="height: 2px;" />

**Settings**
"""
#
# Default data and model settings (i.e., settings used during training)
config_file_train = 'configs/demo.yaml'

# Test-specific data settings
config_file_test = 'configs/config_earthnet2021_test_simulation.yaml'

# Model weights
checkpoint = 'checkpoints/utilise_earthnet2021.pth'
#
# """**Get the data loader**"""
#
# dataloader = get_dataloader_testdata(config_file_train, config_file_test)
#
# """**Instantiate U-TILISE**"""
#
# utilise = Imputation(config_file_train, method='utilise', checkpoint=checkpoint)
#
# """**Apply the model**
#
# U-TILISE operates with a fixed temporal length of 10 images. I.e., U-TILISE processes time series consisting of at most 10 images in one shot, while it employs a sliding window approach to process sequences with more than 10 images.
# """
#
# # Get a data sample
# batch = get_sample(dataloader, sample_index=269)
#
# # Use U-TILISE to impute the satellite image time series
# _, y_pred = utilise.impute_sample(batch)
#
# # Let's visualize the sequences
# brightness_factor = 5
# indices_rgb = batch['c_index_rgb'][0]
#
# fig = visutils.sequence2gallery(batch['x'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Input sequence with artificial data gaps', fontsize=7)
#
# fig = visutils.sequence2gallery(batch['y'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Target sequence', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('U-TILISE imputation', fontsize=7)
#
# """Visualization of the attention masks
# We can visualize the attention masks only for satellite image time series whose temporal length complies with the temporal length of U-TILISE, as we cannot assemble the attention masks for the sliding window approach. For illustration purposes, we temporally trim longer sequences to a maximal temporal length of 10 images by specifying t_start and t_end. After temporal trimming, we apply U-TILISE to impute the chosen subsequence and visualize the corresponding attention masks.
# """
#
# # If the chosen sample comprises more than 10 images:
# # Choose a subsequence consisting of at most 10 images to visualize the attention masks
# t_start = 0
# t_end = 10
#
# # Use U-TILISE to impute the satellite image time series
# batch, y_pred, att = utilise.impute_sample(batch, t_start=t_start, t_end=t_end, return_att=True)
#
# """Visualize the attention masks across all heads for imputing the `t_target`.th frame in the time series:
#
# """
#
# # Specify the index of the target frame (w.r.t. the temporally trimmed sequence)
# # 指定目标帧的索引（相对于时间上修剪过的序列），即输入时间序列中该目标帧的索引，这里输入的时间序列长度为10。
# t_target = 3
#
# fig = visualize_att_for_target_t_across_heads(
#     batch['x'], att, t_target, indices_rgb=indices_rgb, brightness_factor=brightness_factor
# )
#
# """Visualize the attention masks of the `head`.th head across time:"""
#
# head = 0
#
# fig = visualize_att_for_one_head_across_time(
#     batch['x'], att, head=head, indices_rgb=indices_rgb, brightness_factor=brightness_factor
# )
#
# """
# **Comparison to non-learned baselines**
#
# - `last`: copies the last observation
# - `closest`: copies the temporally closest observation
# - `linear_interpolation`: linearly interpolates between the most recent and the next observation"""
#
# last = Imputation(config_file_train, method='trivial', mode='last')
# closest = Imputation(config_file_train, method='trivial', mode='closest')
# interp = Imputation(config_file_train, method='trivial', mode='linear_interpolation')
#
# batch = get_sample(dataloader, sample_index=269)
#
# # Perform imputation for every method
# _, y_pred_utilise = utilise.impute_sample(batch)
# _, y_pred_last = last.impute_sample(batch)
# _, y_pred_closest = closest.impute_sample(batch)
# _, y_pred_interp = interp.impute_sample(batch)
#
# # Let's visualize the results
# brightness_factor = 5
# indices_rgb = batch['c_index_rgb'][0]
#
# fig = visutils.sequence2gallery(batch['x'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Input sequence with artificial data gaps', fontsize=7)
#
# fig = visutils.sequence2gallery(batch['y'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Target sequence', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred_utilise[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('U-TILISE imputation', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred_last[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Baseline: last', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred_closest[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Baseline: closest', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred_interp[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Baseline: linear interpolation', fontsize=7)

"""## Imputation of satellite image time series with real data gaps

<hr style="height: 2px;" />

**Settings**
"""

# # Default data and model settings (i.e., settings used during training)
# config_file_train = 'configs/demo.yaml'
#
# # Test-specific data settings
# config_file_test = 'configs/config_earthnet2021_test.yaml'
#
# # Model weights
# checkpoint = 'checkpoints/utilise_earthnet2021.pth'

"""**Settings**"""

dataloader = get_dataloader_testdata(config_file_train, config_file_test)

"""Instantiate U-TILISE"""

utilise = Imputation(config_file_train, method='utilise', checkpoint=checkpoint)

"""Apply the model"""

# Choose a data sample
batch = get_sample(dataloader, sample_index=294)

# Use U-TILISE to impute the satellite image time series
# _, y_pred = utilise.impute_sample(batch)

# Let's visualize the sequences
# brightness_factor = 5
# indices_rgb = batch['c_index_rgb'][0]
#
# fig = visutils.sequence2gallery(batch['y'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Observed sequence', fontsize=7)
#
# fig = visutils.sequence2gallery(y_pred[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('U-TILISE imputation', fontsize=7)
#
# fig = visutils.sequence2gallery(batch['cloud_mask'][0], variable='binary_mask')
# plt.title('Cloud masks', fontsize=7)

"""# 测试GEE数据

从GEE上获取数据转成Pytorch可用的格式。
"""
import numpy as np
# 读取npy文件，得到data_np数据
my_batch = np.load('data/my_batch.npy', allow_pickle=True).item()
# print(my_batch)

# # 将图像的尺寸填充为128的倍数，不然卷积的时候容易丢失数据，出问题
# H, W = my_batch['x'].shape[-2:]
# maximum = max(H, W)
# # print("maximum:",maximum) # 1102
# n = np.math.ceil(maximum/128)
# # print("n:",n) # 9
# # print(type(my_batch['x'])) # <class 'torch.Tensor'>
#
# padding = [0, 128*n - W, 0, 128*n - H]
# my_batch['x'] = torch.nn.functional.pad(my_batch['x'], padding)
# my_batch['y'] = torch.nn.functional.pad(my_batch['y'], padding)
# my_batch['cloud_mask'] = torch.nn.functional.pad(my_batch['cloud_mask'], padding)
# my_batch['masks'] = torch.nn.functional.pad(my_batch['masks'], padding)
# # print(my_batch['x'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# # print(my_batch['y'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# # print(my_batch['cloud_mask'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# # print(my_batch['masks'].shape) # torch.Size([1, 6, 4, 1152, 1152])

# 替换batch
batch['x'] = my_batch['x'][...,:1024,:1024].to(torch.float)
batch['y'] = my_batch['y'][...,:1024,:1024].to(torch.float)
batch['position_days'] = my_batch['position_days'].to(torch.float)
batch['days'] = my_batch['days'].to(torch.float)
batch['cloud_mask'] = my_batch['cloud_mask'][...,:1024,:1024].to(torch.float)
batch['masks'] = my_batch['masks'][...,:1024,:1024].to(torch.float)
batch['masks_valid_obs'] = my_batch['masks_valid_obs'].to(torch.float)

# 将掩膜覆盖到数据上
masked_data = batch['x'][0].clone()
masked_data[(batch['cloud_mask'][0]).expand(-1, batch['x'][0].shape[1], -1, -1)==0] = 1
batch['x'] = masked_data.unsqueeze(0)


# 预测
_, y_pred = utilise.impute_sample(batch)
print(y_pred.shape)

# y_pred = y_pred[..., :H, :W]
# print(y_pred.shape)

# 保存构建好的my_batch
np.save('data/shenzhen_y_pred.npy', y_pred)
# brightness_factor = 3
# indices_rgb = batch['c_index_rgb'][0]
#
# fig = visutils.sequence2gallery(batch['y'][0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Observed sequence', fontsize=7)
#
#
# fig = visutils.sequence2gallery(y_pred[0], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('U-TILISE imputation', fontsize=7)
#
#
# fig = visutils.sequence2gallery(batch['cloud_mask'][0], variable='binary_mask')
# plt.title('Cloud masks', fontsize=7)

