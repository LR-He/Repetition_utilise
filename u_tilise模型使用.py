# -*- coding: utf-8 -*-
"""U-TILISE模型使用.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VfWrEpYKl3NLV38r4Eot_amZP2ywTATv

# **【注意】**使用模型的时候记得将运行时类型改为GUP
"""

# !git clone https://github.com/prs-eth/U-TILISE.git
#
# !nvcc --version
#
# # !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
# !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
#
# !pip install torchdata
# !pip install torchtext
#
# !pip install -r requ.txt
#
# # !pip install h5py
# # !pip install ipywidgets
# # !pip install ipykernel
# # !pip install kornia
# # !pip install matplotlib
# # !pip install numba
# # !pip install omegaconf
# # !pip install tqdm
# # !pip install wandb
# # !pip install setuptools
# # !pip install prodict
# # !pip install torchgeometry
# # !pip install tensorboard
# # !pip install nestargs
#
# # Commented out IPython magic to ensure Python compatibility.
# # %cd /content/U-TILISE
#
# !pip install torchinfo

# !pip install -U numba

import os
import sys
import torch
from matplotlib import pyplot as plt
from typing import Any, Dict

# /content/U-TILISE
from lib import config_utils
from lib import data_utils
from lib import visutils
from lib.eval_tools import (
    Imputation,
    visualize_att_for_one_head_across_time,
    visualize_att_for_target_t_across_heads
)

# !bash ./scripts/download_checkpoints.sh
#
# # GPU高RAM模式下下载快一点,20分钟左右,CPU下载要半小时。 V100高RAM模式下5分钟能下完。
# # 下载完还要解压，解压也需要一段时间。
# !bash ./scripts/download_data_earthnet2021.sh

def get_dataloader_testdata(
    config_file_train: str,
    config_file_test: str,
    run_mode: str = 'test'
) -> torch.utils.data.dataloader.DataLoader:
    if not os.path.isfile(config_file_train):
        raise FileNotFoundError(f'Cannot find the configuration file used during training: {config_file_train}\n')

    if not os.path.isfile(config_file_test):
        raise FileNotFoundError(f'Cannot find the test configuration file: {config_file_test}\n')

    # Read the configuration file used during training
    config = config_utils.read_config(config_file_train)

    # Merge generic data settings (used during training) with test-specific data settings
    config_testdata = config_utils.read_config(config_file_test)
    config.data.update(config_testdata.data)
    if 'mask' in config_testdata:
        config.mask.update(config_testdata.mask)
    config.misc.run_mode = run_mode

    # Get the data loader
    dset = data_utils.get_dataset(config, phase=run_mode)
    dataloader = torch.utils.data.DataLoader(
        dataset=dset, batch_size=1, shuffle=False, num_workers=8, drop_last=False
    )

    return dataloader


def get_sample(
    dataloader: torch.utils.data.dataloader.DataLoader,
    sample_index: int
) -> Dict[str, Any]:

    batch = dataloader.dataset.__getitem__(sample_index)

    # Introduce the batch dimension (required for the forward pass)
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            batch[k] = v.unsqueeze(0)
        elif isinstance(v, int):
            batch[k] = [v]

    return batch

"""## Imputation of satellite image time series with real data gaps

<hr style="height: 2px;" />

**Settings**
"""

# Default data and model settings (i.e., settings used during training)
config_file_train = 'configs/demo.yaml'

# Test-specific data settings
config_file_test = 'configs/config_earthnet2021_test.yaml'

# Model weights
checkpoint = 'checkpoints/utilise_earthnet2021.pth'

"""**Settings**"""

dataloader = get_dataloader_testdata(config_file_train, config_file_test)

"""Instantiate U-TILISE"""

utilise = Imputation(config_file_train, method='utilise', checkpoint=checkpoint)

"""# 获取GEE数据

"""

# import ee
#
# # 进行身份验证
# ee.Authenticate()
# ee.Initialize()
#
# import numpy as np
# # import tensorflow as tf
# import torch
#
# """*1.* 根据位置信息，获取GEE图像集合"""
#
# # 加载 FAO/GAUL/2015/level2 数据集
# gaul = ee.FeatureCollection('FAO/GAUL/2015/level2');
#
# # 选择深圳的区域，根据 ADM2_NAME 属性过滤
# shenzhen = gaul.filter(ee.Filter.eq('ADM2_NAME', 'Shenzhen'));
#
# # 获取深圳区域的几何信息
# shenzhenGeometry = shenzhen.geometry();
#
# # 位置
# polygon = [ [113.93631717340367,22.60000605357884],
#         [114.04137393609898,22.60000605357884],
#         [114.04137393609898,22.695060891235958],
#         [113.93631717340367,22.695060891235958],
#         [113.93631717340367,22.60000605357884]
#       ]
# region = ee.Geometry.Polygon(polygon)
#
# # 图像集合
# collection = ee.ImageCollection('COPERNICUS/S2')\
#         .filterDate('2020-10-01', '2020-11-01')\
#         .filterBounds(region)
# print(collection.getInfo())
#
# """*2.* 从图像集合中筛选像素覆盖率为100%的图像
#
#
# """
#
# # 求图像集合的中图像的geometry，与自己定义的region区域进行计算，求region是否包含在图像的geometry中。
# # 如果包含则表示该图像能够百分百覆盖region区域，否则不能包含region区域，该图像将被筛除。
# collectionList = collection.toList(collection.size().getInfo())
# # print(collectionList.size().getInfo()) # 12
# # print(type(collectionList.getInfo()[0])) # <class 'dict'>
# # print(type(collectionList.get(1))) # <class 'ee.computedobject.ComputedObject'>
# # print(collectionList.get(1).getInfo()) # {'type': 'Image', 'bands': [...], ......}
#
# # 遍历imageList，计算图像是否百分百覆盖region
# def isFullCovered(image):
#   image_geometry = ee.Image(image).geometry()
#   isContainedIn = region.containedIn(image_geometry) # 小范围是否包含在大范围中
#   return isContainedIn
#
# isFullCoveredList = collectionList.map(isFullCovered)
# # print(isFullCoveredList.getInfo()) # [False, True, False, True, False, True, False, True, False, True, False, True]
# # print(type(isFullCoveredList)) # <class 'ee.ee_list.List'>
#
# isFullCoveredList = isFullCoveredList.getInfo()
# print(isFullCoveredList) # [False, True, False, True, False, True, False, True, False, True, False, True]
# print(type(isFullCoveredList)) # <class 'list'>
#
# # 获取图像集合中每个图像的'system:time_start'属性
# def getTimeStart(image):
#   # image_time_start = ee.Image(image).get('system:time_start')
#   # isContainedIn = region.containedIn(image_geometry) # 小范围是否包含在大范围中
#   return ee.Date(ee.Image(image).get('system:time_start')).format('YYYY-MM-dd')
# timeStartList = collectionList.map(getTimeStart)
# # print(timeStartList.getInfo()) # ['2020-09-01', '2020-09-01', '2020-09-06', '2020-09-06', '2020-09-11', '2020-09-11', '2020-09-16', '2020-09-16', '2020-09-21', '2020-09-21', '2020-09-26', '2020-09-26']
# # print(type(timeStartList)) # <class 'ee.ee_list.List'>
#
# timeStartList = timeStartList.getInfo()
# # print(type(timeStartList)) # <class 'list'>
#
# # 获取图像集合中每个图像的 id
# def getImageId(image):
#   # image_time_start = ee.Image(image).get('system:time_start')
#   # isContainedIn = region.containedIn(image_geometry) # 小范围是否包含在大范围中
#   return ee.Image(image).id()
# imageIdList = collectionList.map(getImageId)
# # print(imageIdList.getInfo()) # ['20200901T025549_20200901T030025_T49QGF', '20200901T025549_20200901T030025_T49QHF', '20200906T025551_20200906T031003_T49QGF', '20200906T025551_20200906T031003_T49QHF', '20200911T025549_20200911T030838_T49QGF', '20200911T025549_20200911T030838_T49QHF', '20200916T025551_20200916T030959_T49QGF', '20200916T025551_20200916T030959_T49QHF', '20200921T025549_20200921T030950_T49QGF', '20200921T025549_20200921T030950_T49QHF', '20200926T025551_20200926T030132_T49QGF', '20200926T025551_20200926T030132_T49QHF']
# # print(type(imageIdList)) # <class 'ee.ee_list.List'>
#
# imageIdList = imageIdList.getInfo()
# # print(type(imageIdList)) # <class 'list'>
#
# # 根据 isFullCoveredList、timeStartList、imageIdList筛选出覆盖率为100%且时间不重叠的图像，并保存在字典中，字典的键表示时间，值表示图像id
# validImageDict = {}
# validImageList = []
# for i in range(len(imageIdList)):
#   if isFullCoveredList[i]: # 覆盖率为100%
#     time_start = timeStartList[i]
#     if time_start not in validImageDict: # 未存在该时间的图像
#       validImageDict[time_start] = imageIdList[i]
#       validImageList.append(ee.Image(collectionList.get(i)))
#
# print(validImageDict) # {'2020-09-01': '20200901T025549_20200901T030025_T49QHF', '2020-09-06': '20200906T025551_20200906T031003_T49QHF', '2020-09-11': '20200911T025549_20200911T030838_T49QHF', '2020-09-16': '20200916T025551_20200916T030959_T49QHF', '2020-09-21': '20200921T025549_20200921T030950_T49QHF', '2020-09-26': '20200926T025551_20200926T030132_T49QHF'}
# # print(len(validImageDict)) # 6
# # print(validImageList) # [<ee.image.Image object at 0x7a46c1db84f0>, <ee.image.Image object at 0x7a46c1dbb220>, <ee.image.Image object at 0x7a46c1dba200>, <ee.image.Image object at 0x7a46c1db9d80>, <ee.image.Image object at 0x7a46c1dbb7f0>, <ee.image.Image object at 0x7a46c1dbb670>]
# # print(len(validImageList)) # 6
#
# print(validImageDict)
#
# """*3.* 根据 QA60 波段计算云掩膜，并将云掩膜作为一个波段添加到原始图像的最后
#
# > **注意：这里的云掩膜与模型中需要的云掩膜相反。**
# *   这里的得到的云掩膜，值为0处，是黑色，表示无效的有云区域，值为1处，是白色，表示有效的无云区域。
# *   模型中需要的云掩膜，值为0处，是黑色，表示无云覆盖的无云区域，值为1处，是白色，表示有云覆盖的有云区域。
#
# """
#
# # validImageList = ee.List(validImageList)
# # print(validImageList.getInfo()) # [{'type': 'Image', 'bands': [......], ......}]
# # print(type(validImageList)) # <class 'ee.ee_list.List'>
# # print(validImageList.get(1).getInfo()) # {'type': 'Image', 'bands': [......], ......}
#
# # QA10和QA20波段是空的，使用QA60波段计算的云掩膜，包含不透明的云和卷云的标记，Bit10标记不透明的云（0为无云，1为有云），Bit11标记卷云（0为无云，1为有云）。
# # 使用QA60波段计算的云掩膜，由于只包含不透明的云和卷云的标记，效果比较差，存在识别不完全的情况，对薄一点的云/雾去识别不出来。
# def getCloudMaskByQA60(image):
#   qa = ee.Image(image).select(['QA60'],['cloud_mask'])
#
#   # Bits 10 and 11 are clouds and cirrus, respectively.
#   cloudBitMask = 1 << 10
#   cirrusBitMask = 1 << 11
#
#   # Both flags should be set to zero, indicating clear conditions.
#   # .eq(0)为True表示有效位置（无云区域），为False表示无效位置（有云区域）
#   # 使用这个方法得到的云掩膜对薄云识别不佳，效果不好
#   mask = ee.Image(qa.bitwiseAnd(cloudBitMask).eq(0))\
#         .And(ee.Image(qa.bitwiseAnd(cirrusBitMask).eq(0)))
#   # return image.updateMask(mask)\
#   #     .select("B.*")\
#   #     .copyProperties(image, ["system:time_start"])
#
#   # 注意：
#   # 返回的结果黑色是有云的区域，是0，表示无效区域，白色是1，表示有效区域。
#   # 返回的结果和模型中需要的云掩膜相反，模型中需要的云掩膜是黑色，值为0，表示未被云覆盖区域，白色，值为1，表示云覆盖区域。
#   return mask
#
#   # 这里将返回的结果取反，就和模型中需要的云掩膜一致，黑色，值为0，表示未被云覆盖区域，白色，值为1，表示云覆盖区域。
#   # return mask.Not() # 后面读数据出错了，报错RasterioIOError: Read or write failed. /vsigs/u-tilise/shenzhen_test/shenzhen_tif_202010/20201031T025839_20201031T030301_T49QHF.tif, band 1: IReadBlock failed at X offset 4, Y offset 4: TIFFReadEncodedTile() failed.
#   # 改回不取反的就不报错了...
#
# def addCloudMask(i):
#   image = ee.List(validImageList).get(i)
#   cloud_mask = ee.Image(cloudMaskList.get(i)).int16()
#   image = ee.Image(image).addBands(cloud_mask,['cloud_mask'])
#   return image
# # 将云掩膜作为一个波段，添加云掩膜波段到原始图像的最后
# cloudMaskList = ee.List(validImageList).map(getCloudMaskByQA60)
# # print(type(cloudMaskList)) # <class 'ee.ee_list.List'>
# # print(cloudMaskList.size().getInfo()) # 6
# # print(cloudMaskList.getInfo()) # [{'type': 'Image', 'bands': [......], ......}]
#
# imageAddCloudMaskList = ee.List.sequence(0,len(validImageList)-1).map(addCloudMask)
# # print(imageAddCloudMaskList.size().getInfo()) # 6
# # print(len(imageAddCloudMaskList.get(0).getInfo()['bands'])) # 17
# # print(imageAddCloudMaskList.get(0).getInfo()['bands'][-1]) # {'id': 'cloud_mask', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 1}, 'dimensions': [1830, 1830], 'crs': 'EPSG:32649', 'crs_transform': [60, 0, 799980, 0, -60, 2600040]}
#
# # # 将云掩膜叠加到原始图像中的最后一层
# # # for循环很慢
# # isContainedInList = []
# # coveredList = []
# # for i in range(imageList.size().getInfo()):
# #   image = imageList.get(i)
# #   image_geometry = ee.Image(image).geometry()
# #   isContainedIn = region.containedIn(image_geometry).getInfo() # 小范围是否包含在大范围中
# #   isContainedInList.append(isContainedIn)
# #   if isContainedIn:
# #     coveredList.append(ee.Image(image))
# # # print(isContainedInList) # [False, True, False, True, False, True, False, True, False, True, False, True]
# # # print(len(coveredList)) # 6
#
# """显示一个图像的掩膜结果"""
#
# # !pip install geemap
# img = ee.Image('COPERNICUS/S2/20201001T025549_20201001T030817_T49QHF')
# image_mask = getCloudMaskByQA60(img)
#
# import geemap
# m = geemap.Map()
# m.addLayer(img, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000}, 'img')
# m.addLayer(ee.Image(image_mask), {'min': 0, 'max': 1}, 'image_mask') # 黑色区域是云
# m.addLayer(img.updateMask(image_mask), {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000}, 'image_masked') # 有云的地方是空白
# display(m)
#
# """*4.* 将包含云掩膜的有效时间序列图像上传到 Cloud Storage
#
# 现在有的数据：
#
# 1. region（ee.Geometry 类型）：图像位置
#
# 2. collectionList（ee.List 类型）：根据日期、位置筛选的原始图像列表
#
# 3. isFullCoveredList（list 类型）：原始图像的像素覆盖率是否百分百覆盖的布尔列表
#
# 4. timeStartList（list 类型）：与原始图像列表的对应的开始时间列表
#
# 5. imageIdList（list 类型）：与原始图像列表的对应的图像 id 列表
#
# 6. validImageDict（dict 类型）：有效时间序列图像的“日期 -- 图像 id”字典
#
# 7. validImageList（list 类型）：有效时间序列原始图像列表
#
# 8. cloudMaskList（ee.List 类型）：有效时间序列原始图像对应的云掩膜列表
#
# 9. imageAddCloudMaskList（ee.List 类型）：包含云掩膜的有效时间序列图像列表
#
#
# """
#
# BUCKET = 'u-tilise'
# FOLDER = 'shenzhen_test'
# KERNEL_SIZE = 256
# KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]
# kernel_buffer = [128, 128]
#
# buffer_region = region.buffer(distance=10*KERNEL_SIZE).getInfo()['coordinates'] # 10 是导出时的分辨率 scale
# regionInfo = region.getInfo()['coordinates']
#
# image_size = collection.first().clip(region).getInfo()['bands'][1]['dimensions']
# print(image_size) # [808, 1076]
#
# """上传数据"""
#
# # 上传数据到 Cloud Storage，不采用 kernel_buffer，直接把原图的所有波段导出
# def exportImageToCloudStorage(out_image_base, image):
#   task = ee.batch.Export.image.toCloudStorage(
#     image = image.int16(),
#     # image = s2image.select(BANDS),
#     description = out_image_base,
#     bucket = BUCKET,
#     fileNamePrefix = FOLDER + '/shenzhen_tif_202010/' + out_image_base,
#     region = regionInfo,
#     # scale = 30,
#     scale = 10,
#     # fileFormat = 'TFRecord', # 默认为tif格式
#     maxPixels = 1e10,
#     # formatOptions = {
#     #   'patchDimensions': KERNEL_SHAPE,
#     #   # 'kernelSize': kernel_buffer,
#     #   'compressed': True,
#     #   'maxFileSize': 104857600
#     # }
#   )
#
#   task.start()
#
# # 由于上传时需要传递参数，参数要通过.getInfo()方法来获得具体的值，而使用.map()方法批量上传时不能使用.getInfo()方法，这里使用for循环上传数据
# for index, (key, value) in enumerate(validImageDict.items()):
#   out_image_base = value
#   image = ee.Image(imageAddCloudMaskList.get(index))
#   exportImageToCloudStorage(out_image_base, image)
#
#   # print(index, key, value)
#   # 0 2020-09-01 20200901T025549_20200901T030025_T49QHF
#   # 1 2020-09-06 20200906T025551_20200906T031003_T49QHF
#   # 2 2020-09-11 20200911T025549_20200911T030838_T49QHF
#   # 3 2020-09-16 20200916T025551_20200916T030959_T49QHF
#   # 4 2020-09-21 20200921T025549_20200921T030950_T49QHF
#   # 5 2020-09-26 20200926T025551_20200926T030132_T49QHF
#
# """*5.* 获取时间序列数据集"""
#
# !gcloud auth login
#
# from google.colab import auth
# auth.authenticate_user()
#
# # # KERNEL_SHAPE = [256, 256]
# # # kernel_buffer = [64, 64]
# # BANDS = ['B2','B3','B4','B8','cloud_mask']
#
# # # 1.获取TFRecoder数据和json文件
# # filesList1 = !gsutil ls 'gs://u-tilise/test'
# # filesList1 = !gsutil ls 'gs://'{BUCKET}'/'{FOLDER}
# # exportFilesList1 = [s for s in filesList1 if '20200901' in s]
# # imageFilesList1 = []
# # jsonFile1 = None
# # for f in exportFilesList1:
# #   if f.endswith('.tfrecord.gz'):
# #     imageFilesList1.append(f)
# #   elif f.endswith('.json'):
# #     jsonFile1 = f
#
# # # Make sure the files are in the right order.
# # imageFilesList1.sort()
#
# # from pprint import pprint
# # pprint(imageFilesList1)
# # print(jsonFile1)
#
# # import json
# # # Load the contents of the mixer file to a JSON object.
# # # TODO:
# # jsonText1 = !gsutil cat {jsonFile1}
# # # 读取并打印JSON文件内容
# # # with open(json_file_path, 'r') as json_file:
# # # with open(user_folder+'/fcnn-demo/prediction/'+jsonFile, 'r') as json_file:
# # # with open(jsonFile, 'r') as json_file:
# # #     jsonText = json_file.read()
# # #     print(jsonText)
# # # Get a single string w/ newlines from the IPython.utils.text.SList
# # mixer1 = json.loads(jsonText1.nlstr)
# # # mixer = json.loads(jsonText)
# # pprint(mixer1)
# # patches = mixer1['totalPatches']
#
# !pip install rasterio
# import rasterio
#
# from datetime import datetime
#
# # 获取tif文件的数据，构建时间序列data_torch_tensor
# filesList = !gsutil ls 'gs://'{BUCKET}'/'{FOLDER}'/shenzhen_tif_202010'
# exportFilesList = [s for s in filesList if '202010' in s]
# exportFilesList.sort()
# imageFilesList = []
# imageNumpyList = []
# metadataDict = None
# for f in exportFilesList:
#   if f.endswith('.tif'):
#     imageFilesList.append(f)
#     # 打开 TIFF 文件
#     with rasterio.open(f, 'r') as src:
#       # 读取 TIFF 文件中的数据，并添加到 imageNumpyList 中
#       tiff_data = src.read()
#       imageNumpyList.append(tiff_data)
#
#       # 获取元数据信息，每个tif的metadata都是一样的，只记录一个就行了
#       if metadataDict is None:
#         metadataDict = src.meta
#
#       # # 打印数据维度和元数据
#       # print("Data Type:", type(tiff_data)) # Data Type: <class 'numpy.ndarray'>
#       # print("Data Shape:", tiff_data.shape) # Data Shape: (17, 1076, 1102)
#       # # 每个tif的metadata都是一样的
#       # print("Metadata Type:", type(metadata)) # Metadata Type: <class 'dict'>
#       # print("Metadata:", metadata) # Metadata: {'driver': 'GTiff', 'dtype': 'int16', 'nodata': None, 'width': 1102, 'height': 1076, 'count': 17, 'crs': CRS.from_epsg(32649), 'transform': Affine(10.0, 0.0, 801680.0, 0.0, -10.0, 2512970.0)}
#
# # # Make sure the files are in the right order.
# imageFilesList.sort()
#
# from pprint import pprint
# pprint(imageFilesList)
#
# data_np = np.stack(imageNumpyList, axis=0)
# # print(data_np.shape) # (6, 17, 1076, 1102)
# # print(type(image_np_data)) # <class 'numpy.ndarray'>
# # print(len(imageNumpyList)) # 6
#
# # 将numpy.array转为torch.tensor，并构建成(B,T,C,H,W)的形式
# data_torch_tensor = torch.from_numpy(data_np).unsqueeze(0)
# # print(type(data_torch_tensor)) # <class 'torch.Tensor'>
# # print(data_torch_tensor.shape) # torch.Size([1, 6, 17, 1076, 1102])
# # print(data_torch_tensor.dtype) # torch.int16
#
# # 将数据缩小为0到1之间，先除以10000，再将大于1的部分设为1，小于0的部分设为0
# # ！！注意：这里云掩膜也被缩小了！！
# data_torch_tensor = torch.clamp(data_torch_tensor / 10000.0, min=0, max=1)
# print(data_torch_tensor.min(), data_torch_tensor.max()) # tensor(0.) tensor(1.)
#
# # 保存data_np为npy文件，以后不用再请求 Cloud Storage
# np.save('/content/drive/MyDrive/U-TILISE/shenzhen_tif_202010.npy',data_np)
# import numpy as np
#
# # 读取npy文件，得到data_np数据
# data_np = np.load('/content/drive/MyDrive/U-TILISE/shenzhen_tif_202010.npy')
# print(data_np.shape)
#
# data_torch_tensor = torch.from_numpy(data_np).unsqueeze(0)
# data_torch_tensor = torch.clamp(data_torch_tensor / 10000.0, min=0, max=1)
# print(data_torch_tensor.shape)
#
# """*6.* 构建 batch 字典的相关参数，以便在模型中使用
#
# 需要构建：
#
# 1. x：时间序列数据，4 个通道
# 2. y：与 x 对应的 GT，没有则为 x
# 3. position_days：时间序列图像中每张图像是当年的第几天
# 4. days：时间序列图像中每张图像与第一张图像相差的天数
# 5. cloud_mask：与 x 对应的云掩膜，1 个通道
# 6. masks：与 cloud_mask 一样
# 7. masks_valid_obs：表示时间序列中的图像是否可用，0为不可用，1为可用
#
# 其他参数暂时不需要构建先。
# """
#
# # x
# data_bgr = data_torch_tensor[:, :, 1:4, :, :]
# data_nir = data_torch_tensor[:, :, 7, :, :].unsqueeze(2)
# x = torch.cat([data_bgr,data_nir],dim=2)
# print(data_bgr.shape, data_nir.shape, x.shape) # torch.Size([1, 6, 3, 1076, 1102]) torch.Size([1, 6, 1, 1076, 1102]) torch.Size([1, 6, 4, 1076, 1102])
#
#
# # position_days
# dateList = list(validImageDict.keys())
# print(dateList) # ['2020-09-01', '2020-09-06', '2020-09-11', '2020-09-16', '2020-09-21', '2020-09-26']
#
# dates = [float(datetime.strptime(str_date, "%Y-%m-%d").timetuple().tm_yday) for str_date in dateList]
# position_days = torch.tensor(np.array(dates)).unsqueeze(0)
# # print(position_days) # tensor([[245., 250., 255., 260., 265., 270.]], dtype=torch.float64)
#
#
# # days
# days = [datetime.strptime(str_date, "%Y-%m-%d") for str_date in dateList] # 获取datetime格式的时间，以便进行减法运算
# days = [day - days[0] for day in days] # 获得时间间隔
# days = [td.days + td.seconds / (24 * 3600) for td in days] # 将时间间隔转为float
# # print(days) # [0.0, 5.0, 10.0, 15.0, 20.0, 25.0]
#
# days = torch.tensor(np.array(days)).unsqueeze(0) # 将列表转化为torch.tensor,并构建成(B,T)形式
# # print(days) # tensor([[ 0.,  5., 10., 15., 20., 25.]], dtype=torch.float64)
#
#
# # cloud_mask、masks、masks_valid_obs
# cloud_mask = data_torch_tensor[:, :, -1, :, :].unsqueeze(2)*10000 # 这里将云掩膜放大到原始大小，0-1
# masks = cloud_mask
# masks_valid_obs = torch.ones(cloud_mask.shape)
# print(cloud_mask.shape, masks_valid_obs.shape) # torch.Size([1, 6, 1, 1076, 1102]) torch.Size([1, 6, 1, 1076, 1102])
# print(cloud_mask.min(),cloud_mask.max()) # tensor(0.) tensor(1.)
#
# print(cloud_mask.dtype) # tensor(0.0244) tensor(1.)
#
# my_batch ={}
# my_batch['x'] = x
# my_batch['y'] = x
# my_batch['position_days'] = position_days
# my_batch['days'] = days
# my_batch['cloud_mask'] = cloud_mask
# my_batch['masks'] = masks
# my_batch['masks_valid_obs'] = masks_valid_obs
# print(my_batch)
#
# # 保存构建好的my_batch
# np.save('/content/drive/MyDrive/U-TILISE/my_batch_shenzhen202010.npy', my_batch)

import numpy as np

# 加载my_batch
my_batch = np.load('data/my_batch_qiqihaer_include_mask_tif_2020-2021_all_months.npy', allow_pickle=True).item()

import torch

# # 将图像的尺寸填充为128的倍数，不然卷积的时候容易丢失数据，出问题
# H, W = my_batch['x'].shape[-2:]
# maximum = max(H, W)
# # print("maximum:",maximum) # 1102
# n = np.math.ceil(maximum/128)
# # print("n:",n) # 9
# # print(type(my_batch['x'])) # <class 'torch.Tensor'>
#
# padding = [0, 128*n - W, 0, 128*n - H]
# my_batch['x'] = torch.nn.functional.pad(my_batch['x'], padding)
# my_batch['y'] = torch.nn.functional.pad(my_batch['y'], padding)
# my_batch['cloud_mask'] = torch.nn.functional.pad(my_batch['cloud_mask'], padding)
# my_batch['masks'] = torch.nn.functional.pad(my_batch['masks'], padding)
# print(my_batch['x'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# print(my_batch['y'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# print(my_batch['cloud_mask'].shape) # torch.Size([1, 6, 4, 1152, 1152])
# print(my_batch['masks'].shape) # torch.Size([1, 6, 4, 1152, 1152])

# 转换cloud_mask，将1变成0，0变成1
# my_batch['cloud_mask'] = my_batch['cloud_mask']*10000
# my_batch['cloud_mask'] = my_batch['cloud_mask'] - 1
# my_batch['cloud_mask'] = my_batch['cloud_mask'] * (-1)
# my_batch['cloud_mask'] = my_batch['cloud_mask'].int()
# my_batch['masks'] = my_batch['cloud_mask'].int()
# print(my_batch['cloud_mask'].min(), my_batch['cloud_mask'].max()) # tensor(0.) tensor(1.)

# 将输入数据添加掩膜
masked_data = my_batch['x'][0].clone()
masked_data[(my_batch['cloud_mask'][0]).expand(-1, my_batch['x'][0].shape[1], -1, -1)==1] = 1
# my_batch['x'] = masked_data.unsqueeze(0)
my_batch['x'] = masked_data.unsqueeze(0)

# 画图检验填充前后的图像，看看填充位置是不是正确的（右边和下边）
# brightness_factor = 3
# indices_rgb = [2,1,0]

# fig = visutils.sequence2gallery(my_batch['y'][0][...,:1024,:1024], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Observed sequence', fontsize=7)
#
# fig = visutils.sequence2gallery(masked_data[0][...,:1024,:1024], indices_rgb=indices_rgb, brightness_factor=brightness_factor)
# plt.title('Input(masked) sequence', fontsize=7)
#
# fig = visutils.sequence2gallery(my_batch['cloud_mask'][0][...,:1024,:1024]==0, variable='binary_mask')
# plt.title('Cloud Mask sequence', fontsize=7)
#
# """*7.* 使用模型做预测"""
#
# !cp /content/drive/MyDrive/U-TILISE/earthnet2021_iid_test_split_simulation.hdf5 /content/U-TILISE/data/earthnet2021_iid_test_split_simulation.hdf5

# 初始化模型u-tilise
# config_file_test = 'configs/config_earthnet2021_test.yaml'
config_file_test = 'configs/config_earthnet2021_test_simulation.yaml'
dataloader = get_dataloader_testdata(config_file_train, config_file_test)
utilise = Imputation(config_file_train, method='utilise', checkpoint=checkpoint)

# 获取原始batch
batch = get_sample(dataloader, sample_index=294)

# 将batch中的部分信息用my_batch中的替换
# batch['x'] = my_batch['x'][...,:1024,:1024].to(torch.float)
# batch['y'] = my_batch['y'][...,:1024,:1024].to(torch.float)
# batch['position_days'] = my_batch['position_days'].to(torch.float)
# batch['days'] = my_batch['days'].to(torch.float)
# batch['cloud_mask'] = my_batch['cloud_mask'][...,:1024,:1024].to(torch.float)
# batch['masks'] = my_batch['masks'][...,:1024,:1024].to(torch.float)
# batch['masks_valid_obs'] = my_batch['masks_valid_obs'].to(torch.float)

batch['x'] = my_batch['x'][...,:512,:512].to(torch.float)
batch['y'] = my_batch['y'][...,:512,:512].to(torch.float)
batch['position_days'] = my_batch['position_days'].to(torch.float)
batch['days'] = my_batch['days'].to(torch.float)
batch['cloud_mask'] = (my_batch['cloud_mask'][...,:512,:512]).to(torch.float)
batch['masks'] = batch['cloud_mask']
batch['masks_valid_obs'] = my_batch['masks_valid_obs'].to(torch.float)

# !set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:16
# import os
# os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:16"

# torch.cuda.empty_cache()  # 释放显存

# !fuser -v /dev/nvidia*
# !kill -9 5763

print(batch)
# 使用模型预测
_, y_pred = utilise.impute_sample(batch)

np.save('data/qiqihaer_include_mask_tif_2020-2021_all_months_y_pred_512.npy', y_pred)

print(y_pred.shape)
